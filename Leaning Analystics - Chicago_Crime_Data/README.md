# ğŸ™ï¸ Chicago Crime Data Analysis (PySpark)

Acest proiect analizeazÄƒ dataset-ul *Chicago Crime* folosind **PySpark**, tehnici Big Data È™i trei modele de Machine Learning.

---

## ğŸ”§ Tehnologii folosite
- PySpark (Spark SQL & MLlib)  
- Google Colab + Google Drive  
- Matplotlib & Seaborn  
- Scikit-learn (metrici + matrice confuzie)

---

## ğŸ“‚ Dataset
Dataset-ul include informaÈ›ii despre infracÈ›iuni din oraÈ™ul Chicago:
- `primary_type`
- `date`, `district`
- `arrest`
- `location_description`, coordonate  
Datele sunt preluate din Google Drive (`Chicago_Crime_Data.csv`).

---

## ğŸ§¼ Preprocesare
- Eliminare valori lipsÄƒ  
- Conversie `date` â†’ timestamp  
- ExtracÈ›ie: `year`, `month`, `hour`, `dayofweek`  
- Conversie `arrest` din boolean â†’ integer  
- PregÄƒtirea datasetului pentru ML (categorice + one-hot encoding)

---

## ğŸ” AnalizÄƒ exploratorie (EDA)
Grafice generate:
- Top 10 tipuri de infracÈ›iuni  
- InfracÈ›iuni pe ani  
- DistribuÈ›ia arest / ne-arest  
- InfracÈ›iuni pe ore

---

## ğŸ¤– Modele ML folosite
- **Logistic Regression**
- **Random Forest**
- **Gradient Boosted Trees (GBT)**

Fiecare model include:
- Matrice de confuzie  
- Classification report (precizie, recall, F1-score)  
- Accuracy   

---

## ğŸ¥‡ Comparare modele
AcurateÈ›ile sunt afiÈ™ate la final sub formÄƒ de listÄƒ:
- Logistic Regression: 0.8668
- Random Forest: 0.9012
- GBT: 0.9145

---

## ğŸ“Œ Concluzii
Proiectul demonstreazÄƒ utilizarea PySpark pentru procesarea datelor mari È™i antrenarea modelelor ML.  
Modelul **GBT** a obÈ›inut cea mai bunÄƒ performanÈ›Äƒ È™i este recomandat pentru predicÈ›ia probabilitÄƒÈ›ii unui arest.